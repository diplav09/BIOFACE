{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_bioface.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZG4hl0MibrBT",
        "outputId": "493a30f7-6acf-4914-a93b-96bd63ad3c8b"
      },
      "source": [
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbWbbMxibtlA",
        "outputId": "5f34cf1d-cdee-45c9-c615-66382e7af606"
      },
      "source": [
        "os.environ['SIR_CONFIG_DIR'] = \"/content/gdrive/My Drive/bioface\"\n",
        "%cd /content/gdrive/My Drive/bioface"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/bioface\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdKDQhdpcP47"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRmMNm4bb4qp"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def conv3x3(in_channels, out_channels, kernel_size, stride, dilation, padding):\n",
        "\treturn nn.Conv2d(in_channels, out_channels, kernel_size,stride, dilation, padding)\n",
        "\n",
        "def conv(in_channels, out_channels, kernel_size, bias= False, padding = 1, stride = 1):\n",
        "\treturn nn.Conv2d(in_channels, out_channels, kernel_size, padding= (kernel_size//2), bias = bias, stride = stride)\n",
        "\n",
        "\n",
        "class SingleConv(nn.Module):\n",
        "\tdef __init__(self, in_channels, out_channels, kernel_size, stride = 1, padding = 1, dilation = 1, groups = 1, relu = True, bn = True, bias = False):\n",
        "\t\tsuper(SingleConv, self).__init__()\n",
        "\t\tself.conv = nn.Conv2d(in_channels, out_channels, kernel_size = kernel_size, stride = stride, padding = padding, dilation = dilation, groups = groups, bias = bias)\n",
        "\t\tself.bn = nn.BatchNorm2d(out_channels, eps = 1e-5, momentum = 0.01, affine = True) if bn else None\n",
        "\t\tself.relu = nn. ReLU() if relu else None\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\tx = self.conv(x)\n",
        "\t\tif self.bn is not None:\n",
        "\t\t\tx = self.bn(x)\n",
        "\t\tif self.relu is not None:\n",
        "\t\t\tx = self.relu(x)\n",
        "\t\treturn x\n",
        "\n",
        "class TripleConv(nn.Module):\n",
        "\tdef __init__(self, in_channels, out_channels, kernel_size, stride = 1, padding = 1, dilation = 1, groups = 1, relu = True, bias = False):\n",
        "\t\tsuper(TripleConv, self).__init__()\n",
        "\t\tself.conv = nn.Sequential(\n",
        "\t\t\tnn.Conv2d(in_channels, out_channels, kernel_size = kernel_size, stride = stride, padding = padding, dilation = dilation, groups = groups, bias = bias),\n",
        "\t\t\tnn.BatchNorm2d(out_channels, eps = 1e-5, momentum = 0.01, affine = True),\n",
        "\t\t\tnn.ReLU(inplace = True),\n",
        "\t\t\tnn.Conv2d(out_channels, out_channels, kernel_size = kernel_size, stride = stride, padding = padding, dilation = dilation, groups = groups, bias = bias),\n",
        "\t\t\tnn.BatchNorm2d(out_channels, eps = 1e-5, momentum = 0.01, affine = True),\n",
        "\t\t\tnn.ReLU(inplace = True),\n",
        "\t\t\tnn.Conv2d(out_channels, out_channels, kernel_size = kernel_size, stride = stride, padding = padding, dilation = dilation, groups = groups, bias = bias),\n",
        "\t\t\tnn.BatchNorm2d(out_channels, eps = 1e-5, momentum = 0.01, affine = True),\n",
        "\t\t\tnn.ReLU(inplace = True)\n",
        "\t\t)\n",
        "\tdef forward(self, x):\n",
        "\t\tx = self.conv(x)\n",
        "\t\treturn x\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "\tdef __init__(self,in_channels):\n",
        "\t\tsuper(Encoder, self).__init__()\n",
        "\t\tself.layer1 = TripleConv(in_channels,32,3)\n",
        "\t\tself.layer2 = TripleConv(32,64,3)\n",
        "\t\tself.layer3 = TripleConv(64,128,3)\n",
        "\t\tself.layer4 = TripleConv(128,256,3)\n",
        "\t\tself.layer5 = TripleConv(256,512,3)\n",
        "\t\tself.mp = nn.MaxPool2d(2,stride = 2)\n",
        "\tdef forward(self, x):\n",
        "\t\tx1  = self.layer1(x)\n",
        "\t\tx1d = self.mp(x1)\n",
        "\t\tx2  = self.layer2(x1d)\n",
        "\t\tx2d = self.mp(x2)\n",
        "\t\tx3  = self.layer3(x2d)\n",
        "\t\tx3d = self.mp(x3)\n",
        "\t\tx4  = self.layer4(x3d)\n",
        "\t\tx4d = self.mp(x4)\n",
        "\t\tx5  = self.layer5(x4d)\n",
        "\t\treturn x1,x2,x3,x4,x5\n",
        "\n",
        "class Up(nn.Module):\n",
        "\tdef __init__(self ,in_channels ,out_channels, bilinear = False):\n",
        "\t\tsuper(Up, self).__init__()\n",
        "\t\tif bilinear:\n",
        "\t\t\tself.up = nn.Upsample(scale_factor = 2, mode = 'bilinear', align_corner = True)\n",
        "\t\telse:\n",
        "\t\t\tself.up = nn.ConvTranspose2d(in_channels, out_channels, 2, stride = 2)\n",
        "\t\tself.conv = TripleConv(out_channels,out_channels, 3)\n",
        "\tdef forward(self, x1, x2):\n",
        "\t\tx1 = self.up(x1)\n",
        "\n",
        "\t\t#to resolve padding issue\n",
        "\t\tdiffY = x2.size()[2] - x1.size()[2]\n",
        "\t\tdiffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "\t\tx1 = F.pad(x1, (diffX // 2, diffX - diffX // 2,\n",
        "\t\t\t\t\t\tdiffY // 2, diffY - diffY //2))\n",
        "\n",
        "\t\t#using add instead of concat to reduce complexity\n",
        "\t\tx = torch.add(x2,x1)\n",
        "\t\tx = self.conv(x)\n",
        "\t\treturn x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "\tdef __init__(self, out_channels):\n",
        "\t\tsuper(Decoder, self).__init__()\n",
        "\t\tself.up1 = Up(512,256)\n",
        "\t\tself.up2 = Up(256,128)\n",
        "\t\tself.up3 = Up(128,64)\n",
        "\t\tself.up4 = Up(64,32)\n",
        "\t\tself.up5 = conv(32, out_channels, 3)\n",
        "\n",
        "\tdef forward(self, x1, x2, x3, x4, x5):\n",
        "\t\tx = self.up1(x5,x4)\n",
        "\t\tx = self.up2(x, x3)\n",
        "\t\tx = self.up3(x, x2)\n",
        "\t\tx = self.up4(x, x1)\n",
        "\t\tx = self.up5(x)\n",
        "\t\treturn x\n",
        "\n",
        "class MultipleDecoder(nn.Module):\n",
        "\tdef __init__(self, in_channels = 3 ,out_channels = 1):\n",
        "\t\tsuper(MultipleDecoder, self).__init__()\n",
        "\t\tself.lightVectorLSize = 15\n",
        "\t\tself.bsize = 2\n",
        "\t\tself.enc  = Encoder(in_channels)\n",
        "\t\tself.dec1 = Decoder(out_channels)\n",
        "\t\tself.dec2 = Decoder(out_channels)\n",
        "\t\tself.dec3 = Decoder(out_channels)\t\t\n",
        "\t\tself.dec4 = Decoder(out_channels)\n",
        "\t\tself.fc1  = SingleConv(512,512,3)  # in code kernel size is given as 4\n",
        "\t\tself.fc2  = nn.Linear(8192,512,1)  # FC layer\n",
        "\t\tself.fc3  = nn.Linear(512,self.lightVectorLSize + self.bsize,1)  # FC layer for lighting and camera parameter+ lighting condition\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\tx1,x2,x3,x4,x5 = self.enc(x)\n",
        "\t\tfmel     = self.dec1(x1,x2,x3,x4,x5)\n",
        "\t\tfblood   = self.dec2(x1,x2,x3,x4,x5)\n",
        "\t\tShading  = self.dec3(x1,x2,x3,x4,x5)\n",
        "\t\tspecmask = self.dec4(x1,x2,x3,x4,x5)\n",
        "\n",
        "\t\ty1 = self.fc1(x5)\n",
        "\t\ty1 = torch.flatten(y1, 1)\n",
        "\t\t# print(y1.size())\n",
        "\t\ty2 = self.fc2(y1)\n",
        "\t\ty3 = self.fc3(y2)\n",
        "\t\t# b,ch,h,w\n",
        "\t\tlightingparameters = y3[:,0:self.lightVectorLSize]\n",
        "\t\tnbatch = y3.size()[0]\n",
        "\t\tlightingparameters = torch.reshape(lightingparameters, (nbatch,self.lightVectorLSize,1,1))\n",
        "\t\t# print(y3.size())\n",
        "\t\tb = torch.reshape( y3[:,self.lightVectorLSize:self.lightVectorLSize + self.bsize], (nbatch, self.bsize,1,1))\n",
        "\t\treturn lightingparameters,b,fmel,fblood,Shading,specmask\n",
        "\n",
        "def Net():\n",
        "  model = MultipleDecoder(in_channels = 3 ,out_channels = 1)\n",
        "  return model\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u1h3tAucUfP"
      },
      "source": [
        "Utils.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NheAC6MjcAFA"
      },
      "source": [
        "import numpy as np\n",
        "import cv2,os,math,sys\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torch.optim import Adam\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def load_matfiles(data_path):\n",
        "\tillF = loadmat(data_path + 'illF.mat')\n",
        "\tillF = illF['illF']  # 1x 33 x 12\n",
        "\t\n",
        "\tillumDmeasured = loadmat(data_path + 'illumDmeasured.mat')\n",
        "\tillumDmeasured = illumDmeasured['illumDmeasured']\t\n",
        "\n",
        "\tillumA = loadmat(data_path + 'illumA.mat')\n",
        "\tillumA = illumA['illumA']\n",
        "\n",
        "\tNewskincolour = loadmat(data_path + 'Newskincolour.mat')\n",
        "\tNewskincolour = Newskincolour['Newskincolour']\n",
        "\n",
        "\trgbCMF = loadmat(data_path + 'rgbCMF.mat')\n",
        "\trgbCMF = rgbCMF['rgbCMF']\n",
        "\n",
        "\tTmatrix = loadmat(data_path + 'Tmatrix.mat')\n",
        "\tTmatrix = Tmatrix['Tmatrix']\n",
        "\n",
        "\tXYZspace = loadmat(data_path + 'XYZspace.mat')\n",
        "\tXYZspace = XYZspace['XYZspace']\n",
        "\n",
        "\treturn illF, illumDmeasured, illumA, Newskincolour, rgbCMF, Tmatrix, XYZspace\n",
        "# to scale the parameter \n",
        "def ScaleNet(lightingparameters,b,fmel,fblood,Shading,specmask,bSize):\n",
        "#     weightA  : B x 1 x 1 x 1  \n",
        "#     weightD  : B x 1 x 1 x 1  \n",
        "#     CCT      : B x 1 x 1 x 1  \n",
        "#     Fweights : B x 12 x 1 x 1  \n",
        "#     b        : B x 2 x 1 x 1  \n",
        "#     fmel     : B x 1 x 224 x 224  \n",
        "#     fblood   : B x 1 x 224 x 224  \n",
        "#     Shading  : B x 1 x 224 x 224  \n",
        "#     specmask : B x 1 x 224 x 224  \n",
        "#     bSize    : 2\n",
        "  nbatch = lightingparameters.size()[0]\n",
        "  m = nn.Softmax(dim=1)\n",
        "  lightingweights = m(lightingparameters[:,0:14,:,:])\n",
        "  weightA  = lightingweights[:,0,:,:]\n",
        "  weightA = torch.unsqueeze(weightA,1)\n",
        "  weightD  = lightingweights[:,1,:,:]\n",
        "  weightD = torch.unsqueeze(weightD,1)\n",
        "  Fweights = lightingweights[:,2:14,:,:]\n",
        "  CCT      =  lightingparameters[:,14,:,:]\n",
        "  CCT      = ((22 - 1) / (1 + torch.exp(-CCT))) + 1;\n",
        "  CCT = torch.unsqueeze(CCT,1)\n",
        "  b = 6.*(torch.sigmoid(b))-3\n",
        "  BGrid = torch.reshape(b,(bSize,1,1,nbatch)) # 2 x 1 x 1 x B check this reshape\n",
        "  BGrid = BGrid / 3\n",
        "  fmel = torch.sigmoid(fmel) *2 -1\n",
        "  fblood = torch.sigmoid(fblood) * 2 -1\n",
        "  Shading = torch.exp(Shading)\n",
        "  specmask = torch.exp(specmask)\n",
        "  return weightA,weightD,CCT,Fweights,b,BGrid,fmel,fblood,Shading,specmask\n",
        "\n",
        "# create the illumination model from CIE standard illuminants: A,D,F\n",
        "# extract illumA,illumDNorm,illumFNorm foom mat files in util\n",
        "def illuminationModel(weightA,weightD,Fweights,CCT,illumA,illumDNorm,illumFNorm):\n",
        "#     weightA    : B x 1 x 1 x 1 \n",
        "#     weightD    : B x 1 x 1 x 1\n",
        "#     CCT        : B x 1 x 1 x 1\n",
        "#     Ftype      : B x 12 x 1 x 1 \n",
        "#     illumA     : 1 x 1 x 33 x B\n",
        "#     illumDNorm : 1 x 1 x 33 x 22\n",
        "#     illumFNorm : 1 x 1 x 33 x 12\n",
        "  illumA = illumA.permute(3,2,0,1)  # B x 33 x 1 x 1\n",
        "  # print(illumA.size(),weightA.size())\n",
        "  illuminantA = illumA * weightA # B x 33 x 1 x 1\n",
        "\n",
        "  # don't know this layer. check where function vl_nnillumD is defined \n",
        "  # illumDlayer = Layer.fromFunction(@vl_nnillumD);\n",
        "  # illD   = illumDlayer(CCT,illumDNorm);\n",
        "  # illuminantD = illD.*weightD;\n",
        "\n",
        "  # illuminantD should be converted to B x 33 x 1 x 1\n",
        "  illumDNorm = illumDNorm.permute(3,2,0,1) # 22 x 33 x 1 x 1\n",
        "  illumDNorm = torch.unsqueeze(torch.sum(illumDNorm,0),0) # 1 x 33 x 1 x 1\n",
        "  # print(illumDNorm.size(),CCT.size(),weightD.size())\n",
        "  illuminantD = CCT*illumDNorm*weightD  \n",
        "\n",
        "  illumFNorm = illumFNorm.permute(0,2,3,1) #permute to 1 x 33 x 12 x 1\n",
        "  Fweights = Fweights.permute(2,3,1,0)\n",
        "  illuminantF = illumFNorm*Fweights # 1 x 33 x 12 x B\n",
        "  illuminantF = torch.unsqueeze(torch.sum(illuminantF,2),2) # check if dimension is reduced 1 x 33 x 1 x B\n",
        "  illuminantF = illuminantF.permute(3,1,0,2) # B x 33 x 1 x 1\n",
        "  e = illuminantA + illuminantD +illuminantF\n",
        "  esum = torch.unsqueeze(torch.sum(e,1),1) # sum across channel\n",
        "  e = e / esum\n",
        "\n",
        "  return e\n",
        "\n",
        "def cameraModel(mu,PC,b,wavelength):\n",
        "# Inputs:\n",
        "#     mu         : B x 1 x 1 x 1 \n",
        "#     PC         : B x 1 x 1 x 1 ?? actually is 99 x 2\n",
        "#     b          : B x 2 x 1 x 1 \n",
        "#     wavelength : 33\n",
        "\n",
        "# Outputs:\n",
        "#     Sr,Sg,Sb   : B x 33 x 1 x 1\n",
        "\n",
        "    nbatch = b.size()[0]\n",
        "    ## PCA model\n",
        "    b = torch.reshape(b,(nbatch,2)).float()\n",
        "    PC = torch.reshape(PC,(99,2)).float()\n",
        "    # print(b.size(),PC.size())\n",
        "    S = torch.matmul(PC,torch.transpose(b, 0, 1))  # 99 x nbatch\n",
        "    mu = torch.unsqueeze(mu,1)\n",
        "    S = S + mu  \n",
        "    rel = nn.ReLU()\n",
        "    S =  rel(S)\n",
        "    S = torch.transpose(S, 0, 1)\n",
        "    # print(S.size())\n",
        "    wavelength = wavelength.int()    \n",
        "    ## split up S into Sr, Sg, Sb \n",
        "    Sr = torch.reshape(S[:,0:wavelength],(nbatch, wavelength, 1, 1))                  \n",
        "    Sg = torch.reshape(S[:,wavelength:wavelength*2],(nbatch, wavelength, 1, 1))     \n",
        "    Sb = torch.reshape(S[:,wavelength*2:wavelength*3],(nbatch, wavelength, 1, 1))\n",
        "\n",
        "    return Sr,Sg,Sb \n",
        "\n",
        "def CameraSensitivityPCA(rgbCMF):\n",
        "\n",
        "  X = np.zeros((99,28))\n",
        "  Y = np.zeros((99,28))\n",
        "  redS = rgbCMF[0,0]\n",
        "  greenS= rgbCMF[0,1]\n",
        "  blueS = rgbCMF[0,2]\n",
        "  for i in range(0,28):\n",
        "    Y[0:33,i]  = redS[:,i] / np.sum(redS[:,i])\n",
        "    Y[33:66,i] = greenS[:,i] / np.sum(greenS[:,i])\n",
        "    Y[66:99,i] = blueS[:,i] / np.sum(blueS[:,i])\n",
        "  pca = PCA(n_components=28)\n",
        "  pca.fit(Y.T)\n",
        "  PC = pca.components_    # 99,27\n",
        "  EV = pca.explained_variance_  # 27,1\n",
        "  mu = pca.mean_  # 1,99\n",
        "  PC = np.matmul(PC.T[:,0:2],np.diag(np.sqrt(EV[0:2])))\n",
        "  EV = EV[0:2]\n",
        "  # [PC,~,EV,~,explained,mu] = pca(Y')\n",
        "  # PC = single(PC(:,1:2)*diag(sqrt(EV(1:2)))) # 99,2  \n",
        "  # mu = single(mu')  # 99,1\n",
        "  # EV = single(EV(1:2)) # 2,1\n",
        "  return mu,PC,EV\n",
        "\n",
        "def computelightcolour(e,Sr,Sg,Sb):\n",
        "# Inputs:\n",
        "#     Sr,Sg,Sb         : B x 33 x 1 x 1 \n",
        "#     e                : B x 33 x 1 x 1\n",
        "#  Output:\n",
        "#  lightcolour         : Bx 3 x 1 x 1 \n",
        "  lightcolour  = torch.cat((torch.sum(Sr * e,1), torch.sum(Sg * e,1), torch.sum(Sb * e,1)),1)\n",
        "  lightcolour = torch.unsqueeze(lightcolour,2)\n",
        "  return lightcolour\n",
        "\n",
        "def computeSpecularities(specmask,lightcolour):\n",
        "# Inputs:\n",
        "#     specmask          : B x 1 x H x W \n",
        "#     lightcolour      : B x 3 x 1 x 1 \n",
        "#  Output:\n",
        "#     Specularities    : B x 1 x H x W \n",
        "##\n",
        "\tSpecularities = specmask * lightcolour\n",
        "\treturn  Specularities \n",
        "\n",
        "def BiotoSpectralRef(fmel,fblood,Newskincolour):\n",
        "# Inputs:\n",
        "#     fmel             : B x 1 x H x W \n",
        "#     fblood           : B x 1 x H x W\n",
        "#     Newskincolour    : B x 33 x 256 x 256 \n",
        "#  Output:\n",
        "#     R_total          : B x 33 x H x W \n",
        "##\n",
        "\tBiophysicalMaps = torch.cat((fblood,fmel),1) # B x 2 x H x W \n",
        "\tBiophysicalMaps = BiophysicalMaps.permute(0, 2, 3, 1) # for troch grid shape should be B x H x W x 2  \n",
        "\n",
        "\n",
        "\tR_total  = nn.functional.grid_sample(Newskincolour, BiophysicalMaps, mode='bilinear')\n",
        "\treturn R_total \n",
        "\n",
        "def ImageFormation (R_total, Sr,Sg,Sb,e,Specularities,Shading):\n",
        "\t#Inputs:,\n",
        "\t#     R_total       : nbatch X 33 X H X W \n",
        "\t#     Shading       : nbatch X 1 X H X W \n",
        "\t#     Specularities : nbatch X 1 X H X W \n",
        "\t#     Sr,Sg,Sb      : nbatch x 33 x 1 x 1 \n",
        "\t#     e             : nbatch x 33 x 1 x 1 \n",
        "\t# Output:\n",
        "\t#     rgbim : nbatch x 1 x H x  W \n",
        "\t#---------------------------Image Formation -------------------------------\n",
        "\tspectraRef = R_total * e # nbatch X 33 X H X W  \n",
        "\t#--------------------------------------------------------------------------\n",
        "\trChannel = torch.unsqueeze(torch.sum(spectraRef * Sr,1),1)  \n",
        "\tgChannel = torch.unsqueeze(torch.sum(spectraRef * Sg,1),1)  \n",
        "\tbChannel = torch.unsqueeze(torch.sum(spectraRef * Sb,1),1)  \n",
        "\n",
        "\tdiffuseAlbedo = torch.cat((rChannel,gChannel,bChannel),1)  # nbatch x 3 x H x W \n",
        "\n",
        "\t#---------------------------Shaded Diffuse --------------------------------\n",
        "\n",
        "\tShadedDiffuse = diffuseAlbedo * Shading  # nbatch x 3 x H x W\n",
        "\n",
        "\t# ShadedDiffuse = torch.unsqueeze(torch.sum(ShadedDiffuse,1),1) #added for dimension correction\n",
        "\t#---------------------------Raw appearance --------------------------------\n",
        "\trawAppearance = ShadedDiffuse + Specularities \n",
        "\treturn rawAppearance,diffuseAlbedo  \n",
        "\n",
        "def WhiteBalance(rawAppearance,lightcolour):\n",
        "# Inputs:\n",
        "#     rawAppearance    : B x 3 x H x W \n",
        "#     lightcolour      : B x 3 x 1 x 1  \n",
        "#  Output:\n",
        "#     ImwhiteBalanced  : B x 3 x H x W \n",
        "## --------------------------- White Balance ------------------------------\n",
        "\tWBrCh = torch.unsqueeze(rawAppearance[:,0,:,:]/lightcolour[:,0,:,:],1)  \n",
        "\tWBgCh = torch.unsqueeze(rawAppearance[:,1,:,:]/lightcolour[:,1,:,:],1)\n",
        "\tWBbCh = torch.unsqueeze(rawAppearance[:,2,:,:]/lightcolour[:,2,:,:],1)\n",
        "\tImwhiteBalanced = torch.cat((WBrCh,WBgCh,WBbCh),1)\n",
        "\treturn ImwhiteBalanced\n",
        "\n",
        "def findT(Tmatrix,BGrid):\n",
        "# Inputs:\n",
        "#     Tmatrix          : 128 x 128 x 9 \n",
        "#     BGrid            : 2 x 1 x 1 x B \n",
        "#  Output:\n",
        "#     T_RAW2RGB        :  B x 9 x 1 x 1\n",
        "##\n",
        "    # to make dimesion B x 9 x 128 x 128\n",
        "\tnbatch = BGrid.size()[3] \n",
        "\tTmatrix = torch.unsqueeze(Tmatrix,0)\n",
        "\tTmatrix = Tmatrix.permute(0,3,1,2) # 1 x 9 x 128 x 128\n",
        "\tTmatrix = Tmatrix.repeat(nbatch,1,1,1) # B x 9 x 128 x 128\n",
        "\n",
        "\tBGrid = BGrid.permute(3,1,2,0) # B x 1 x 1 x 2 to match grid dimension\n",
        "\t\n",
        "\tT_RAW2XYZ =  nn.functional.grid_sample(Tmatrix,BGrid, mode='bilinear')\n",
        "\t#T_RAW2RGB.name ='T_RAW2RGB';\n",
        "\treturn T_RAW2XYZ\n",
        "\n",
        "def fromRawTosRGB(imWB,T_RAW2XYZ):\n",
        "\n",
        "# Inputs:\n",
        "#     imWB: B X 3 X H X W  \n",
        "#     T_RAW2RGB  :  B x 9 x 1 x 1\n",
        "# Output:\n",
        "#     sRGBim : B X 3 X H X W\n",
        "##\n",
        "\tIx = T_RAW2XYZ[:,0,:,:] * imWB[:,0,:,:] + T_RAW2XYZ[:,3,:,:] * imWB[:,1,:,:] + T_RAW2XYZ[:,6,:,:] * imWB[:,2,:,:] # B X 1 X H X W\n",
        "\tIy = T_RAW2XYZ[:,1,:,:] * imWB[:,0,:,:] + T_RAW2XYZ[:,4,:,:] * imWB[:,1,:,:] + T_RAW2XYZ[:,7,:,:] * imWB[:,2,:,:] \n",
        "\tIz = T_RAW2XYZ[:,2,:,:] * imWB[:,0,:,:] + T_RAW2XYZ[:,5,:,:] * imWB[:,1,:,:] + T_RAW2XYZ[:,8,:,:] * imWB[:,2,:,:] \n",
        "\tIx = torch.unsqueeze(Ix,1)\n",
        "\tIy = torch.unsqueeze(Iy,1)\n",
        "\tIz = torch.unsqueeze(Iz,1)\n",
        "\tIxyz = torch.cat((Ix,Iy,Iz),1) # B X 3 X H X W\n",
        "\tTxyzrgb = torch.tensor([3.2406, -1.5372, -0.4986, -0.9689, 1.8758, 0.0415, 0.0557, -0.2040, 1.057 ])\n",
        "\n",
        "\t# if isa(imWB, 'Layer')\n",
        "\t#   Txyzrgb = Param('value',Txyzrgb,'learningRate',0); Txyzrgb.name='Txyzrgb';\n",
        "\t# end \n",
        "\n",
        "\tR = Txyzrgb[0] * Ixyz[:,0,:,:] + Txyzrgb[3] * Ixyz[:,1,:,:] + Txyzrgb[6] * Ixyz[:,2,:,:]  # R\n",
        "\tG = Txyzrgb[1] * Ixyz[:,0,:,:] + Txyzrgb[4] * Ixyz[:,1,:,:] + Txyzrgb[7] * Ixyz[:,2,:,:]  # G\n",
        "\tB = Txyzrgb[2] * Ixyz[:,0,:,:] + Txyzrgb[5] * Ixyz[:,1,:,:] + Txyzrgb[8] * Ixyz[:,2,:,:]  # B\n",
        "\n",
        "\tR = torch.unsqueeze(R,1)\n",
        "\tG = torch.unsqueeze(G,1)\n",
        "\tB = torch.unsqueeze(B,1)\n",
        "\tsRGBim = torch.cat((R,G,B),1)\n",
        "\trel = nn.ReLU()\n",
        "\tsRGBim =  rel(sRGBim)\n",
        "\treturn sRGBim \n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Vy6xLEfcaIf"
      },
      "source": [
        "Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pvxzHg1cD24"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from scipy import misc\n",
        "import numpy as np\n",
        "import imageio\n",
        "import torch\n",
        "import os\n",
        "\n",
        "to_tensor = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "class LoadData(Dataset):\n",
        "\n",
        "  def __init__(self, dataset_dir = './zx_7_d10_inmc_celebA_01.hdf5', test=False):\n",
        "\n",
        "    filename = dataset_dir\n",
        "    with h5py.File(filename, \"r\") as f:\n",
        "      # List all groups\n",
        "      a_group_key = list(f.keys())[0]\n",
        "      # Get the data\n",
        "      self.data = list(f[a_group_key])        \n",
        "\n",
        "    self.dataset_size = len(self.data)\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.dataset_size\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    itm = self.data[idx]\n",
        "    image = np.asarray(itm[0:3,:,:])\n",
        "\n",
        "    diffuse = np.asarray(itm[3:4,:,:])\n",
        "\n",
        "    mask =  np.asarray(itm[6:7,:,:])\n",
        "\n",
        "    return image, diffuse, mask"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czeTD1DhcJ0j"
      },
      "source": [
        "import numpy as np\n",
        "import cv2,os,math,sys\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torch.optim import Adam\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import imageio\n",
        "import h5py\n",
        "\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "\n",
        "dataset_dir = '/content/gdrive/My Drive/bioface/zx_7_d10_inmc_celebA_01.hdf5'\n",
        "data_path = '/content/gdrive/My Drive/bioface/'\n",
        "batch_size = 32\n",
        "learning_rate = 1e-5\n",
        "num_train_epochs = 200\n",
        "init_epoch = 0\n",
        "blossweight = 1e-4  \n",
        "appweight = 1e-2 * 5\n",
        "Shadingweight = 1e-5 \n",
        "sparseweight = 1e-5\n",
        "load_checkpoint_path = None"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s73F8wSfceGM"
      },
      "source": [
        "def loss_L2_regularization(output):\n",
        "    loss = torch.sum(torch.square(output))\n",
        "    return loss\n",
        "def loss_shade(predictedShading, actualshading, actualmasks):\n",
        "\tscale = torch.sum( torch.sum( (actualshading * predictedShading) * actualmasks, 2), 2) / torch.sum( torch.sum( torch.square(predictedShading) * actualmasks, 2), 2)\n",
        "\n",
        "\tscale = torch.reshape(scale,(batch_size,1,1,1))\n",
        "\tpredictedShading = predictedShading * scale\n",
        "\talpha = (actualshading - predictedShading) * actualmasks\n",
        "\tloss = torch.sum(torch.square(alpha))\n",
        "\treturn loss\n",
        "def loss_L1_regularization(output):\n",
        "    loss = torch.sum(output)\n",
        "    return loss\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8CcACtPcmW1"
      },
      "source": [
        "Train code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBsi3bzIcgk8"
      },
      "source": [
        "def train_model():\n",
        "\t# setup.m executed\n",
        "\tillF, illumDmeasured, illumA, Newskincolour, rgbCMF, Tmatrix, XYZspace = load_matfiles(data_path)\n",
        "\tNewskincolour = np.transpose(Newskincolour, (2, 0, 1))  # 256x 256 X 33 -> 33 X 256 X 256\n",
        "\tNewskincolour = np.tile(Newskincolour,(batch_size,1,1,1))\n",
        "\tmu,PC,EV = CameraSensitivityPCA(rgbCMF)\n",
        "\tLightVectorSize = 15\n",
        "\twavelength = torch.tensor(33.)\n",
        "\tbSize = torch.tensor(2)\n",
        "\tillF = illF.reshape((1,1,33,12))\n",
        "\tillumDmeasured = illumDmeasured.T.reshape((1,1,33,22))\n",
        "\tillumA = illumA.astype(np.float32) / np.sum(illumA)             # 1,1,33\n",
        "\tillumA = np.expand_dims(illumA, axis=3)\n",
        "\tillumA = np.tile(illumA,(1,1,1,batch_size))  # additional line\n",
        "\tillumDNorm = illumDmeasured.astype(np.float32)\n",
        "\tfor i in range(0,22):\n",
        "\t\tillumDNorm[:,:,:,i] = illumDmeasured[:,:,:,i] / np.sum(illumDmeasured[:,:,:,i])\n",
        "\n",
        "\tillumFNorm = illF.astype(np.float32)\n",
        "\tfor i in range(0,12):\n",
        "\t\tillumFNorm[:,:,:,i] = illF[:,:,:,i] / np.sum(illF[:,:,:,i])\n",
        "\n",
        "\tcelebaimdb_averageImage = torch.tensor([129.1863,104.7624,93.5940])\n",
        "\tmuim = torch.reshape(celebaimdb_averageImage,(1,3,1,1))\n",
        "\tbSize = 2\n",
        "\n",
        "\tillumA = torch.from_numpy(illumA).cuda()\n",
        "\tillumDNorm = torch.from_numpy(illumDNorm).cuda()\n",
        "\tillumFNorm = torch.from_numpy(illumFNorm).cuda()\n",
        "\tmu = torch.from_numpy(mu).cuda()\n",
        "\tPC = torch.from_numpy(PC).cuda()\n",
        "\tNewskincolour = torch.from_numpy(Newskincolour).cuda()\n",
        "\tTmatrix = torch.from_numpy(Tmatrix).cuda()\n",
        "\tprint(\"pre proc done\")\n",
        "\n",
        "\ttorch.backends.cudnn.deterministic = True\n",
        "\tdevice = torch.device(\"cuda\")\n",
        "\n",
        "\ttrain_dataset = LoadData(dataset_dir, test=False)\n",
        "\ttrain_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=1,\n",
        "\t\t\t\t\t\t  pin_memory=True, drop_last=True)\n",
        "\tmodel = MultipleDecoder() \n",
        "\tmodel = torch.nn.DataParallel(model) # multi GPU\n",
        "\toptimizer = Adam(params=model.parameters(), lr=learning_rate)\n",
        "\n",
        "\tif load_checkpoint_path is not None:\n",
        "\t\tcheckpoint = torch.load(load_checkpoint_path)\n",
        "\t\tmodel.load_state_dict(checkpoint, strict=True)\n",
        "\t\tprint(\"check point loaded\")\n",
        "\t# Loss define\n",
        "\tMSE_loss = torch.nn.MSELoss()\n",
        "\tprint(\"train start\")\n",
        "\tfor epoch in range(init_epoch,num_train_epochs):\n",
        "\n",
        "\t\ttorch.cuda.empty_cache()\n",
        "\n",
        "\t\ttrain_iter = iter(train_loader)\n",
        "\t\ttrain_loss = 0\n",
        "\t\tfor i in range(len(train_loader)):\n",
        "\n",
        "\t\t\toptimizer.zero_grad()\n",
        "\t\t\timages, actualshading, actualmasks = next(train_iter)\n",
        "\t\t\timages = images.to(device, non_blocking=True).float()\n",
        "\t\t\tactualshading = actualshading.to(device, non_blocking=True)\n",
        "\t\t\tactualmasks = actualmasks.to(device, non_blocking=True)\n",
        "\t\t\tlightingparameters,b,fmel,fblood,Shading,specmask = model(images)\n",
        "\n",
        "\t\t\tweightA,weightD,CCT,Fweights,b,BGrid,fmel,fblood,Shading,specmask = ScaleNet(lightingparameters,b,fmel,fblood,Shading,specmask,bSize)\n",
        "\t\t\te = illuminationModel(weightA,weightD,Fweights,CCT,illumA,illumDNorm,illumFNorm)\n",
        "\t\t\tSr,Sg,Sb = cameraModel(mu.float(),PC.float(),b,wavelength)\n",
        "\t\t\tlightcolour = computelightcolour(e,Sr.float(),Sg.float(),Sb.float())\n",
        "\t\t\tSpecularities = computeSpecularities(specmask,lightcolour)\n",
        "\t\t\tR_total = BiotoSpectralRef(fmel,fblood,Newskincolour)\n",
        "\t\t\trawAppearance,diffuseAlbedo = ImageFormation (R_total, Sr,Sg,Sb,e,Specularities,Shading)\n",
        "\t\t\tImwhiteBalanced = WhiteBalance(rawAppearance,lightcolour)\n",
        "\t\t\tT_RAW2XYZ = findT(Tmatrix,BGrid)\n",
        "\t\t\tsRGBim = fromRawTosRGB(ImwhiteBalanced,T_RAW2XYZ)\n",
        "\t\t\trel = nn.ReLU()\n",
        "\t\t\tsRGBim = rel(sRGBim)\n",
        "\t\t\t# Camera parameter loss:\n",
        "\t\t\tpriorloss = loss_L2_regularization(b)\n",
        "\t\t\t# L2: appearance loss\n",
        "\t\t\tappearanceloss = MSE_loss(sRGBim , images)\n",
        "\n",
        "\t\t\tshadingloss = loss_shade(Shading, actualshading, actualmasks)\n",
        "\t\t\t# L1 sparsity loss\n",
        "\t\t\tsparsityloss = loss_L1_regularization(Specularities)\n",
        "\n",
        "\t\t\ttotal_loss = blossweight * priorloss + appweight * appearanceloss + Shadingweight * shadingloss + sparseweight * sparsityloss\n",
        "\t\t\ttrain_loss += total_loss.item()\n",
        "\t\t\ttotal_loss.backward()\n",
        "\t\t\toptimizer.step()\n",
        "\t\ttrain_loss = train_loss / len(train_loader)\n",
        "\t\tprint(\"train_loss == \",train_loss , \"  epoch == \",epoch)\n",
        "\t\tmodel.eval().cpu()\n",
        "\t\ttorch.save(model.state_dict(), \"models/cnn_epoch_\" + str(epoch) + \".pth\")\n",
        "\t\tmodel.to(device).train()\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nHywMBSck5U"
      },
      "source": [
        "train_model()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}